# # -*- coding: utf-8 -*-
# from pythainlp.tokenize import word_tokenize

# # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Lexicon ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
# POSITIVE_WORDS = ["‡∏î‡∏µ", "‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°", "‡∏™‡∏ß‡∏¢", "‡∏ä‡∏≠‡∏ö", "‡∏ñ‡∏π‡∏Å‡πÉ‡∏à", "‡∏£‡∏±‡∏Å", "‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°"]
# NEGATIVE_WORDS = ["‡πÅ‡∏¢‡πà", "‡πÑ‡∏°‡πà‡∏î‡∏µ", "‡∏ä‡πâ‡∏≤", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à", "‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á", "‡πÄ‡∏ö‡∏∑‡πà‡∏≠", "‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à"]

# def analyze_sentiment(text):
#     """
#     ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
#     ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: 'positive', 'negative', 'neutral'
#     """
#     if not text or not isinstance(text, str):
#         return 'neutral'

#     tokens = word_tokenize(text)
#     pos_count = sum(1 for t in tokens if t in POSITIVE_WORDS)
#     neg_count = sum(1 for t in tokens if t in NEGATIVE_WORDS)

#     if pos_count > neg_count:
#         return 'positive'
#     elif neg_count > pos_count:
#         return 'negative'
#     else:
#         return 'neutral'

# # ---------------------------
# # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î
# # ---------------------------
# if __name__ == "__main__":
#     test_texts = [
#         "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°",
#         "‡∏ä‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à",
#         "‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©",
#         "",
#         None
#     ]

#     for text in test_texts:
#         result = analyze_sentiment(text)
#         print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}\nSentiment: {result}\n")
from bs4 import BeautifulSoup
import pandas as pd

# üßπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏á HTML ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
def clean_html(text):
    """‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏ó‡πá‡∏Å HTML ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏ß‡∏ô"""
    if text:
        return BeautifulSoup(text, "html.parser").get_text().replace("\n", " ").strip()
    return text

data = {
    "review_id": [10391984933, 10391994936, 10396240713],
    "review": [
        # ‚úÖ ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà 1 (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á)
        "<p>‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á <b>‡πÇ‡∏≠‡∏£‡∏¥‡∏á</b> ‡∏ó‡∏µ‡πà‡∏™‡∏±‡πà‡∏á‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏à‡∏∏‡∏î "
        "‡∏™‡∏±‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏≥‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏£‡πâ‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡πÑ‡∏ß "
        "‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏Å‡πá‡∏î‡∏µ</p>",

        # ‚úÖ ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà 2 (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ tag)
        "<ul><li>‡∏õ‡∏¥‡∏î‡∏ú‡∏ô‡∏∂‡∏Å‡∏ß‡∏≤‡∏•‡πå‡∏ß‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û</li>"
        "<li>‡∏õ‡∏∞‡πÄ‡∏Å‡πá‡∏ô‡∏¢‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô</li>"
        "<li>‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡πä‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏∏‡πà‡∏ô</li>"
        "<li>‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà‡∏ó‡∏î‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ</li>"
        "<li>‡πÅ‡∏´‡∏ß‡∏ô‡∏¢‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏±‡πà‡∏ß</li>"
        "<li>‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏´‡∏•‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏ö‡∏£‡∏∑‡πà‡∏ô</li></ul>",

        # ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà 3 (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
        "<p>‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ö‡∏∏‡∏ö ‡πÅ‡∏ï‡πà‡∏Ç‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ</p>"
    ]
}

# üîß ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏à‡∏≥‡∏•‡∏≠‡∏á
df = pd.DataFrame(data)

# üß† ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô clean_html ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå review
df["clean_review"] = df["review"].apply(clean_html)

# üé® ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
print("="*60)
print("üßæ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á HTML ‡∏î‡πâ‡∏ß‡∏¢ clean_html()")
print("="*60)

for _, row in df.iterrows():
    print("platform: shopee")
    print(f"‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ID: {row['review_id']} ")
    print(f"review: {row['review']} ")
    print(f"clean review : {row['clean_review']}")
    print("-"*60)
