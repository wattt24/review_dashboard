# line_oa_processing.py
from transformers import pipeline
import pandas as pd
import psycopg2

import plotly.express as px
import streamlit as st
from database.all_database import get_connection
import pandas as pd
from database.all_database import get_connection

def inspect_line_messages(limit=10):
    conn = get_connection()
    query = f"SELECT * FROM line_messages ORDER BY created_at DESC LIMIT {limit};"
    df = pd.read_sql(query, conn)
    conn.close()

    print("üß± ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô line_messages:")
    print(df.columns.tolist())
    print("\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print(df.head())

    print(f"\n‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df)} ‡πÅ‡∏ñ‡∏ß")
    return df
def fetch_line_messages(limit=50):
    conn = get_connection()
    query = f"""
        SELECT id, user_id, message, created_at
        FROM line_messages
        WHERE message_type = 'text'
          AND direction = 'user'
          AND message IS NOT NULL
        ORDER BY created_at DESC
        LIMIT {limit};
    """
    df = pd.read_sql(query, conn)
    conn.close()
    print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß {len(df)} ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
    return df

def check_unique_values():
    conn = get_connection()
    df = pd.read_sql("SELECT message_type, direction, COUNT(*) FROM line_messages GROUP BY message_type, direction;", conn)
    conn.close()
    print(df)
    return df
# ==========================
# 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
# ==========================
def get_classifier():
    print("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• zero-shot classification...")
    return pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")




# ==========================
# 3Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
# ==========================
def classify_message(text, classifier):
    labels = ["‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", "‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "‡∏Ñ‡∏≥‡∏ä‡∏°", "‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"]
    try:
        result = classifier(text, candidate_labels=labels, multi_label=False)
        if result and "labels" in result and "scores" in result:
            return result["labels"][0], float(result["scores"][0])
        else:
            return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ", 0.0
    except Exception as e:
        print(f"‚ö†Ô∏è classify_message error: {e}")
        return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ", 0.0


# ==========================
# 4Ô∏è‚É£ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ==========================
def analyze_messages(df):
    if df.empty:
        df["category"] = []
        df["confidence"] = []
        return df

    classifier = get_classifier()
    results = [classify_message(x, classifier) for x in df["message"]]
    df["category"], df["confidence"] = zip(*results)
    return df


def analyze_and_display_all():
    df = fetch_line_messages()
    if df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
        return
    
    classifier = get_classifier()
    print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")

    results = [classify_message(msg, classifier) for msg in df["message"]]
    df["category"], df["confidence"] = zip(*results)
    
    print("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
    pd.set_option("display.max_rows", None)  # ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
    pd.set_option("display.max_colwidth", None)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°
    print(df[["message", "category", "confidence"]])

def summarize_categories(df):
    summary = df["category"].value_counts().reset_index()
    summary.columns = ["Category", "Count"]
    summary["Percent"] = (summary["Count"] / len(df) * 100).round(2)
    return summary

def summarize_confidence(df):
    summary = df.groupby("category")["confidence"].agg(
        ['count', 'mean', 'max']
    ).sort_values(by="mean", ascending=False).reset_index()
    summary.rename(columns={
        "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
        "mean": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
        "max": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"
    }, inplace=True)
    summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"] = summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"].round(3)
    summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"] = summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"].round(3)
    return summary
