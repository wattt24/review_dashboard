# from database.all_database import 
import pandas as pd
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import pymysql,re,json
from dateutil.relativedelta import relativedelta
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus.common import thai_stopwords
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
# Initialize Thai sentiment analyzer
stopwords = set(thai_stopwords())
# def get_connection():
#     return pymysql.connect(
#         host="yamanote.proxy.rlwy.net",
#         user="root",
#         password="yeiIByLVJqRlPrzKLGaNCNySevvHeabG",
#         port=49296,
#         database="railway",
#         charset="utf8mb4"
#     )

def get_connection():
    return pymysql.connect(
        host="localhost",           # ‚úÖ ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î
        user="root",        # üîë ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å DirectAdmin
        password="651324",   # üîê ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å DirectAdmin
        database="reviews_insight", # üóÑÔ∏è ‡∏ä‡∏∑‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ
        port=3306,                  # ‚öôÔ∏è ‡∏û‡∏≠‡∏£‡πå‡∏ï MySQL ‡∏õ‡∏Å‡∏ï‡∏¥
        charset="utf8mb4",          # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        cursorclass=pymysql.cursors.DictCursor
    )
def clean_html(text):
    if text:
        return BeautifulSoup(text, "html.parser").get_text().replace("\n", " ").strip()
    return text


# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ tokenizer (‡∏ó‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö)
model_name = "FlukeTJ/distilbert-base-thai-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# def analyze_For_sentiment(text: str):
#     # ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà string
#     if not text or not isinstance(text, str):
#         print("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß")
#         return 'neutral'

#     # ‚úÖ ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 512 token ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
#     inputs = tokenizer(
#         text,
#         return_tensors="pt",
#         truncation=True,   # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å
#         max_length=512,    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
#         padding=False
#     )
#     if "token_type_ids" in inputs:
#         del inputs["token_type_ids"]

#     with torch.no_grad():
#         outputs = model(**inputs)
#         probs = F.softmax(outputs.logits, dim=-1)
#         labels = ["negative", "neutral", "positive"]
#         idx = torch.argmax(probs, dim=-1).item()

#     return labels[idx]

NEGATIVE_KEYWORDS = ["‡πÅ‡∏ï‡∏Å", "‡πÄ‡∏™‡∏µ‡∏¢", "‡∏´‡πà‡∏ß‡∏¢", "‡∏û‡∏±‡∏á", "‡πÅ‡∏¢‡πà", "‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏ä‡πâ‡∏≤", "‡πÑ‡∏°‡πà‡∏î‡∏µ", "‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤"]

def analyze_For_sentiment(text: str):
    if not text or not isinstance(text, str):
        return 'neutral'

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≥‡∏•‡∏ö‡∏Å‡πà‡∏≠‡∏ô
    if any(word in text for word in NEGATIVE_KEYWORDS):
        rule_based = 'negative'
    else:
        rule_based = None

    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    if "token_type_ids" in inputs:
        del inputs["token_type_ids"]

    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=-1)
        labels = ["negative", "neutral", "positive"]
        idx = torch.argmax(probs, dim=-1).item()
        model_sentiment = labels[idx]

    # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏é‡πÄ‡∏à‡∏≠‡∏Ñ‡∏≥‡∏•‡∏ö ‚Üí ‡πÉ‡∏ä‡πâ rule-based
    if rule_based:
        return rule_based
    return model_sentiment

def extract_keywords(text):
    if text:
        tokens = [w for w in word_tokenize(text) if w.isalpha() and w not in stopwords]
        return json.dumps(tokens, ensure_ascii=False)  # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON string
    return json.dumps([])

#‡πÇ‡∏ï‡∏Å‡∏•‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° ‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤
# def save_reviews_to_db(reviews: list, platform: str, shop_id: str):
#     """
#     ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏≤‡∏á: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå + ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
#     reviews: List ‡∏Ç‡∏≠‡∏á dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ key:
#         - id (review_id)
#         - review (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß)
#         - date_created
#         - rating (optional)
#         - product_id (optional)
    
#     platform: ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° ‡πÄ‡∏ä‡πà‡∏ô 'shopee', 'wordpress', 'facebook'
#     shop_id: ‡∏£‡∏´‡∏±‡∏™‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
#     """
#     if not reviews:
#         print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
#         return

#     conn = get_connection()
#     cursor = conn.cursor()

#     for r in reviews:
#         review_id = str(r.get("id")).strip()
#         raw_text = r.get("review", "")
#         review_text = clean_html(raw_text)
#         review_date = r.get("date_created")
#         rating = r.get("rating")
#         product_id = r.get("product_id")

#         # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
#         sentiment = analyze_For_sentiment(review_text)
#         keywords = extract_keywords(review_text)

#         # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
#         sql = """
#         INSERT INTO reviews_history 
#         (platform, shop_id, product_id, review_id, rating, review_text, sentiment, keywords, review_date, recorded_at)
#         VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
#         ON DUPLICATE KEY UPDATE 
#             rating = VALUES(rating),
#             review_text = VALUES(review_text),
#             sentiment = VALUES(sentiment),
#             keywords = VALUES(keywords),
#             review_date = VALUES(review_date)
#         """

#         cursor.execute(sql, (
#             platform,
#             shop_id,
#             product_id,
#             review_id,
#             rating,
#             review_text,
#             sentiment,
#             json.dumps(keywords, ensure_ascii=False) if isinstance(keywords, (dict, list)) else keywords,
#             review_date
#         ))

#     conn.commit()
#     cursor.close()
#     conn.close()

#     print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß {len(reviews)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° '{platform}' ‡πÅ‡∏•‡πâ‡∏ß")
def save_reviews_to_db(reviews: list, platform: str, shop_id: str):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏•‡∏≤‡∏á: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå + ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    reviews: List ‡∏Ç‡∏≠‡∏á dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ key:
        - id (review_id)
        - review (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß)
        - date_created
        - rating (optional)
        - product_id (optional)
    
    platform: ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° ‡πÄ‡∏ä‡πà‡∏ô 'shopee', 'wordpress', 'facebook'
    shop_id: ‡∏£‡∏´‡∏±‡∏™‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
    """
    if not reviews:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
        return

    conn = get_connection()
    cursor = conn.cursor()

    for r in reviews:
        review_id = str(r.get("id")).strip()
        raw_text = r.get("review", "")
        review_text = clean_html(raw_text)
        review_date = r.get("date_created")
        rating = r.get("rating")
        product_id = r.get("product_id")

        # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‚Üí ‡πÉ‡∏ä‡πâ rating ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô sentiment
        if not review_text:
            if rating in [1, 2]:
                sentiment = "negative"
            elif rating == 3:
                sentiment = "neutral"
            elif rating in [4, 5]:
                sentiment = "positive"
            else:
                sentiment = "neutral"  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ rating ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç
            keywords = json.dumps([])  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á keyword
        else:
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
            sentiment = analyze_For_sentiment(review_text)
            keywords = extract_keywords(review_text)

        # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        sql = """
        INSERT INTO reviews_history 
        (platform, shop_id, product_id, review_id, rating, review_text, sentiment, keywords, review_date, recorded_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
        ON DUPLICATE KEY UPDATE 
            rating = VALUES(rating),
            review_text = VALUES(review_text),
            sentiment = VALUES(sentiment),
            keywords = VALUES(keywords),
            review_date = VALUES(review_date)
        """

        cursor.execute(sql, (
            platform,
            shop_id,
            product_id,
            review_id,
            rating,
            review_text,
            sentiment,
            json.dumps(keywords, ensure_ascii=False) if isinstance(keywords, (dict, list)) else keywords,
            review_date
        ))

    conn.commit()
    cursor.close()
    conn.close()

    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß {len(reviews)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏° '{platform}' ‡πÅ‡∏•‡πâ‡∏ß")

# ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å database ‡∏à‡∏∞ print ‡∏î‡∏π ‡∏´‡∏£‡∏∑‡∏≠ ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏ô‡∏à‡∏≠‡πÑ‡∏î‡πâ  ‡∏î‡∏∂‡∏áreviews_history‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
def get_all_reviews(platform=None, shop_id=None, limit=None):
    conn = get_connection()
    cursor = conn.cursor(pymysql.cursors.DictCursor)

    sql = "SELECT * FROM reviews_history"
    params = []

    if platform or shop_id:
        sql += " WHERE "
        conditions = []
        if platform:
            conditions.append("platform = %s")
            params.append(platform)
        if shop_id:
            conditions.append("shop_id = %s")
            params.append(shop_id)
        sql += " AND ".join(conditions)

    sql += " ORDER BY review_date DESC"

    if limit:
        sql += " LIMIT %s"
        params.append(limit)

    cursor.execute(sql, params)
    results = cursor.fetchall()
    cursor.close()
    conn.close()

    df = pd.DataFrame(results)
    print(f"‚úÖ ‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return df


# def get_reviews_by_period(platform=None, shop_id=None, months=1):
#     from database.all_database import get_connection
#     import pymysql, pandas as pd

#     conn = get_connection()
#     cursor = conn.cursor(pymysql.cursors.DictCursor)

#     # ‡πÉ‡∏ä‡πâ relativedelta ‡∏•‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ
#     start_date = datetime.now() - relativedelta(months=months)

#     sql = "SELECT * FROM reviews_history WHERE review_date >= %s"
#     params = [start_date]

#     if platform:
#         sql += " AND platform = %s"
#         params.append(platform)
#     if shop_id:
#         sql += " AND shop_id = %s"
#         params.append(shop_id)

#     sql += " ORDER BY review_date DESC"

#     cursor.execute(sql, params)
#     results = cursor.fetchall()
#     cursor.close()
#     conn.close()

#     df = pd.DataFrame(results)
#     return df

def get_reviews_by_period(platform=None, shop_id=None, months=None):


    conn = get_connection()
    cursor = conn.cursor(pymysql.cursors.DictCursor)
    params = []

    if months is not None:
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        start_date = datetime.now() - relativedelta(months=int(months))
        sql = "SELECT * FROM reviews_history WHERE review_date >= %s"
        params.append(start_date)
        if platform:
            sql += " AND platform = %s"
            params.append(platform)
        if shop_id:
            sql += " AND shop_id = %s"
            params.append(shop_id)
    else:
        # ‡∏î‡∏∂‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        sql = "SELECT * FROM reviews_history"
        if platform or shop_id:
            sql += " WHERE "
            conditions = []
            if platform:
                conditions.append("platform = %s")
                params.append(platform)
            if shop_id:
                conditions.append("shop_id = %s")
                params.append(shop_id)
            sql += " AND ".join(conditions)

    sql += " ORDER BY review_date DESC"

    cursor.execute(sql, params)
    results = cursor.fetchall()
    cursor.close()
    conn.close()

    return pd.DataFrame(results)
