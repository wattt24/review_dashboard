
# import streamlit as st
# from utils.config import FACEBOOK_PAGE_HEATER_ID, FACEBOOK_PAGE_BBQ_ID
# from api.facebook_graph_api import get_page_info, get_page_posts, get_page_reviews


# # ============================ ‡∏™‡πà‡∏ß‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô UI ============================

# def render_page_info(page_info, page_id):#‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏à (‡∏ä‡∏∑‡πà‡∏≠ ‡πÇ‡∏•‡πÇ‡∏Å‡πâ ID)
#     if "error" in page_info:
#         st.error(f"‚ùå Facebook API error: {page_info['error']}")
#         return

#     name = page_info.get("name", "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏à")
#     picture = page_info.get("picture", {}).get("data", {}).get("url", "")

#     st.markdown(
#         f"""
#         <div style="
#             background-color:#f9f9f9;
#             padding:20px;
#             border-radius:15px;
#             text-align:center;
#             box-shadow:2px 2px 8px rgba(0,0,0,0.1);
#             margin-bottom:20px;">
#             <img src="{picture}" width="80" style="border-radius:50%;">
#             <h3 style="margin:10px 0;">{name}</h3>
#             <p>Page ID: {page_id}</p>
#         </div>
#         """,
#         unsafe_allow_html=True
#     )

# def render_page_posts(posts, num_posts: int):
#     """‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"""
#     st.subheader(f"üìù ‡πÇ‡∏û‡∏™‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î {num_posts} ‡πÇ‡∏û‡∏™‡∏ï‡πå")
#     if not posts:
#         st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á")
#         return

#     for post in posts:
#         message = post.get("message", "(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)")[:100]
#         st.markdown(f"- [{message}...]({post['permalink_url']}) - {post['created_time']}")


# def render_page_reviews(reviews, num_reviews: int):
#     """‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"""
#     st.subheader(f"‚≠ê ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î {num_reviews} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
#     if not reviews:
#         st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏à‡∏ô‡∏µ‡πâ")
#         return

#     for r in reviews:
#         reviewer = r.get("reviewer", {}).get("name", "Anonymous")
#         rating_type = r.get("recommendation_type", "")
#         review_text = r.get("review_text", "")
#         created_time = r.get("created_time", "")
#         st.markdown(f"- **{reviewer}** | {rating_type} | {review_text} | {created_time}")


# # ============================ ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏´‡∏•‡∏±‡∏Å (Main App) ============================

# st.title("üìò Facebook Pages Overview")

# for page_id in [FACEBOOK_PAGE_HEATER_ID, FACEBOOK_PAGE_BBQ_ID]:
#     page_info = get_page_info(page_id)
#     render_page_info(page_info, page_id)

#     posts = get_page_posts(page_id, limit=3)
#     render_page_posts(posts, num_posts=3)

#     reviews = get_page_reviews(page_id, limit=5)
#     render_page_reviews(reviews, num_reviews=5)

# ‡∏ü‡∏£‡∏µ 100% ‡πÉ‡∏ä‡πâ HuggingFace
# from transformers import pipeline
# import pandas as pd
# import psycopg2

# import plotly.express as px
# import streamlit as st
# from database.all_database import get_connection
# import pandas as pd
# from database.all_database import get_connection

# def inspect_line_messages(limit=10):
#     conn = get_connection()
#     query = f"SELECT * FROM line_messages ORDER BY created_at DESC LIMIT {limit};"
#     df = pd.read_sql(query, conn)
#     conn.close()

#     print("üß± ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô line_messages:")
#     print(df.columns.tolist())
#     print("\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
#     print(df.head())

#     print(f"\n‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df)} ‡πÅ‡∏ñ‡∏ß")
#     return df
# def fetch_line_messages(limit=50):
#     conn = get_connection()
#     query = f"""
#         SELECT id, user_id, message, created_at
#         FROM line_messages
#         WHERE message_type = 'text'
#           AND direction = 'user'
#           AND message IS NOT NULL
#         ORDER BY created_at DESC
#         LIMIT {limit};
#     """
#     df = pd.read_sql(query, conn)
#     conn.close()
#     print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß {len(df)} ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
#     return df

# def check_unique_values():
#     conn = get_connection()
#     df = pd.read_sql("SELECT message_type, direction, COUNT(*) FROM line_messages GROUP BY message_type, direction;", conn)
#     conn.close()
#     print(df)
#     return df
# # ==========================
# # 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
# # ==========================
# def get_classifier():
#     print("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• zero-shot classification...")
#     return pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")




# # ==========================
# # 3Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
# # ==========================
# def classify_message(text, classifier):
#     labels = ["‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", "‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "‡∏Ñ‡∏≥‡∏ä‡∏°", "‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"]
#     try:
#         result = classifier(text, candidate_labels=labels, multi_label=False)
#         if result and "labels" in result and "scores" in result:
#             return result["labels"][0], float(result["scores"][0])
#         else:
#             return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ", 0.0
#     except Exception as e:
#         print(f"‚ö†Ô∏è classify_message error: {e}")
#         return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ", 0.0


# # ==========================
# # 4Ô∏è‚É£ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# # ==========================
# def analyze_messages(df):
#     if df.empty:
#         df["category"] = []
#         df["confidence"] = []
#         return df

#     classifier = get_classifier()
#     results = [classify_message(x, classifier) for x in df["message"]]
#     df["category"], df["confidence"] = zip(*results)
#     return df


# def analyze_and_display_all():
#     df = fetch_line_messages()
#     if df.empty:
#         print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
#         return
    
#     classifier = get_classifier()
#     print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")

#     results = [classify_message(msg, classifier) for msg in df["message"]]
#     df["category"], df["confidence"] = zip(*results)
    
#     print("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
#     # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
#     pd.set_option("display.max_rows", None)  # ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
#     pd.set_option("display.max_colwidth", None)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ï‡πá‡∏°
#     print(df[["message", "category", "confidence"]])

# def summarize_categories(df):
#     summary = df["category"].value_counts().reset_index()
#     summary.columns = ["Category", "Count"]
#     summary["Percent"] = (summary["Count"] / len(df) * 100).round(2)
#     return summary

# def summarize_confidence(df):
#     summary = df.groupby("category")["confidence"].agg(
#         ['count', 'mean', 'max']
#     ).sort_values(by="mean", ascending=False).reset_index()
#     summary.rename(columns={
#         "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
#         "mean": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
#         "max": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"
#     }, inplace=True)
#     summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"] = summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"].round(3)
#     summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"] = summary["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î"].round(3)
#     return summary


# if __name__ == "__main__":
    # # check_unique_values()
    # inspect_line_messages(10)
    # analyzed_df = analyze_messages(10)
    # print("üéØ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    # print(analyzed_df[["message", "category", "confidence"]].head())
    # inspect_line_messages(10)
    
    # # 2. ‡∏î‡∏π‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    # check_unique_values()
    
    # # 3. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    # analyzed_df = analyze_messages(34)
    
    # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    # print("üéØ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    # print(analyzed_df[["message", "category", "confidence"]].head())
    # print(analyzed_df.loc[10:15, ["message", "category", "confidence"]])
    # analyze_and_display_all()



    # st.title("üìä LINE Messages Dashboard")

    # st.info("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÇ‡∏î‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•")

    # # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    # df_messages = fetch_line_messages()
    # st.write(f"‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å line messages {len(df_messages)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # # ‡∏õ‡∏∏‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    # with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°..."):
    #     df_analyzed = analyze_messages(df_messages)

    # # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á scrollable
    
    # st.success("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")
    # category_summary = summarize_categories(df_analyzed)
    # # ‡∏™‡∏£‡πâ‡∏≤‡∏á pie chart
    # fig_category = px.pie(
    #     category_summary,
    #     names="Category",
    #     values="Count",
    #     title="üìä ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏° Category",
    #     color_discrete_sequence=px.colors.qualitative.Set2
    # )
    # st.plotly_chart(fig_category, use_container_width=True)

    # # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    # confidence_summary = summarize_confidence(df_analyzed)
    # # ‡∏™‡∏£‡πâ‡∏≤‡∏á bar chart
    # fig_confidence = px.bar(
    #     confidence_summary,
    #     x="category",
    #     y="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
    #     color="category",
    #     text="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢",
    #     title="üìä ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏° Category",
    #     color_discrete_sequence=px.colors.qualitative.Set3
    # )
    # fig_confidence.update_traces(textposition='outside')
    # fig_confidence.update_layout(yaxis=dict(range=[0,1]))
    # st.plotly_chart(fig_confidence, use_container_width=True)

    # # ‡πÅ‡∏™‡∏î‡∏á DataFrame ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    # st.subheader("üìã ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡πâ‡∏ß")
    # st.dataframe(
    #     df_analyzed[["message", "category", "confidence"]].sort_values(by="confidence", ascending=False),
    #     height=600
    # )

# -*- coding: utf-8 -*-
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ tokenizer
model_name = "FlukeTJ/distilbert-base-thai-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def analyze_sentiment(text: str):
    inputs = tokenizer(text[:512], return_tensors="pt")  # ‡∏ï‡∏±‡∏î 512 token
    # ‡∏•‡∏ö token_type_ids ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
    if "token_type_ids" in inputs:
        del inputs["token_type_ids"]
    
    outputs = model(**inputs)
    probs = F.softmax(outputs.logits, dim=-1)
    labels = ["negative", "neutral", "positive"]
    idx = torch.argmax(probs, dim=-1).item()
    return labels[idx], probs[0, idx].item()

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö


# üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
 
    text = "‡πÉ‡∏ä‡πâ‡∏î‡∏µ‡∏à‡πâ‡∏≤ ‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏î‡∏µ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏Ñ‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÅ‡∏ñ‡∏°‡∏™‡πà‡∏á‡∏ü‡∏£‡∏µ ‡∏õ‡∏¥‡πâ‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏ö‡∏≤‡∏ö‡∏µ‡∏Å‡πâ‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡∏ß‡∏∏‡∏Å‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ô‡πÉ‡∏à‡∏Ñ‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞ ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 4 ‡∏Ñ‡∏ô ‡∏ñ‡πâ‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏≤‡∏ô‡πÑ‡∏õ ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏≤"
    sentiment, confidence = analyze_sentiment(text)
    print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
    print(f"Sentiment: {sentiment}, Confidence: {confidence:.3f}")